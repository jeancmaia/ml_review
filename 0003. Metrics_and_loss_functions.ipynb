{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94433abb-ef8d-4bb2-b26b-76e3abd24758",
   "metadata": {},
   "source": [
    "Loss functions for `regression`, `classification`.    \n",
    "Evaluation metrics for `regression`, `classification`, `unsupervised`, and `Recommender system`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c594b-b3b2-4610-aea1-9bdd3ff1038a",
   "metadata": {},
   "source": [
    "-----\n",
    "#### `Loss Function`   \n",
    "\n",
    "A Machine Learning model leverages a Loss Function throughout the fitting/optimization step. It is key for models to learn about playing a specific role in the world. ML models generally combines a Loss function and a optimization algorithm for finding the best inner-parameters.\n",
    "\n",
    "* Regression    \n",
    "For a regression problem, we aim to reduce residuals between the predicted and the actual datum. Let's take a peek at the list with the foremost Regression Loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec41f8a-057b-43ea-8e05-f59cff55708b",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. L2 loss, MSE, quadratic Loss. It is the most used Loss Function due its stead and consistent convergence. Its weakness is the sensibility to outliers.\n",
    "\n",
    "$$ MSE = \\frac{\\sum_{i=1}^{n} (y_i - y_i^p)^2}{n}$$\n",
    "\n",
    "\n",
    "2. L1 loss, MAE, Absolute Loss. Its convergence is harder for the most of optimization algorithms, but it reliable on outliers.\n",
    "\n",
    "$$ MAE = \\frac{\\sum_{i=1}^{n} |y_i - y_i^p|}{n}$$\n",
    "\n",
    "3. Huber Loss, Smooth Mean absolute error. It has the parameter $\\delta$ which smooth the to MSE, when it gets closer to 0; MAE to $\\infty$.\n",
    "\n",
    "4. Log-Cosh Loss. It uses the logarithm of the hyperbolic cosine of the prediction error. Its twice differentiable, ML model might leverage a second-order optimzation algorithm.\n",
    "\n",
    "$$ LogCosh = \\sum_{i=1}^{n}log(cosh(y_i^p - y_i)   $$\n",
    "\n",
    "https://heartbeat.comet.ml/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799027a-9330-432f-ada0-c32516b11bec",
   "metadata": {},
   "source": [
    "* Classification     \n",
    "\n",
    "1. Binary Cross-Entropy Loss / Log Loss\n",
    "\n",
    "$$ L = -\\frac{1}{m}\\sum_{i=1}^{m}(y_i \\cdot log(\\hat{y_i}) + (1-y_i) \\cdot log(1-\\hat{y_i}) )$$\n",
    "\n",
    "\n",
    "2. Hinge Loss   \n",
    "\n",
    "$$ L = max(0, 1 - y \\cdot f(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5036f7f-f225-4cdf-8580-6e12f9ba2c15",
   "metadata": {},
   "source": [
    "-----\n",
    "#### `Evaluation metrics` are generally applied on a cross-validation process to assess the further expected performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d143f4-d7b0-418e-9970-45f56bbbe9d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Regression    \n",
    "\n",
    "Metrics: MAE, MSE, RMSE, RMSLE, MAPE.\n",
    "\n",
    "MAE: Robust to Outliers; Outputs at the same unit of outcome variable. Its not differentiable.     \n",
    "MSE: Differentiable. Sensible outliers; It outputs on a square scale.    \n",
    "RMSE: Outputs at the same unit of outcome variable. Not as Robust as MAE.     \n",
    "RMSLE: Very handy for non-gaussian outcomes.    \n",
    "MAPE: It retrieves the percentage MAE, relative to the actual value.   \n",
    "\n",
    "* Classification   \n",
    "\n",
    "Metrics: F1, Accuracy, Cohen Kappa, and Mathews Correlation Coefficient throughout different thresholds; ROC AUC score; Precision-Recall; Cumulative Gain Chart; Lift Curve; KS-Plot.     \n",
    "https://neptune.ai/blog/evaluation-metrics-binary-classification \n",
    "\n",
    "* Unsupervised   \n",
    "\n",
    "Internal Validation metrics for Hard-clustering.      \n",
    "        1. Partitional, and Density models: Calisnki-Harabasz, Hartigan index, Xu coefficient, Silhouette coefficient.     \n",
    "        2. Hierarchical Methods: Cophenetic Correlation Coefficient, Hubert Statistic. \n",
    "\n",
    "https://arxiv.org/abs/1905.05667\n",
    "\n",
    "\n",
    "* Recommender System   \n",
    "\n",
    "Metrics for evaluating recommender systems rely on algorithm fashion. Content-based filtering generally leverages similarity metrics, whereas collaborative on scores. Metrics: Precision@k, Recall@k, MCC, AP@k, and NDCG.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57485df4-3898-4937-80ee-8e8b3d159c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
