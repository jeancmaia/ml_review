{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a505c7",
   "metadata": {},
   "source": [
    "Following my review notes, in the 8th notebook, I review recommender systems techniques. I'll be focusing on classical approaches with good mentions of contemporary and state of the art techniques.        \n",
    "\n",
    "Classical methods can be split into two main classes: Collaborative or Feature-Based. In the former, algorithms roll out recommendations based on historical data, whereas the latter do it based on similarities among users or items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e949bac",
   "metadata": {},
   "source": [
    "### 1 - Feature-Based methods\n",
    "\n",
    "\n",
    "Before dwelling on Feature-Based algorithms, we must discuss two important concepts: `Item Characterization` and `User Characterization`.     \n",
    "\n",
    "\n",
    "`Item Characterization` is the process of crafting a feature vector for an item. Those features may come from different traits of our items, in which they are stickly related. We behold three foremost techniques: categorization, bag of words, and topic modeling.\n",
    "\n",
    "--------------\n",
    "\n",
    "Categorization. Items are labeled by a predefined taxonomy. To epitomise, a news taxonomy may consists in \"US\", \"World\", \"Business\". An item can be categorize in a set of classes by human labelling or statistical methods. Hastie et all(2009), Mitchell(1997), and Sebastiani(2002).   \n",
    "\n",
    "Bag Of Words. It is a design pattern that transforms a text corpus into a feature vector. Generally, each word becomes a dimension and there are three methods to map an item into the vector space. `WordCount`, `TF`, `TF-IDF`. Sparse Matrices are key for an optimal process. Transforming n-word to bi or tri-grams. Reducing Dimensionality can also help not falling in the curse of dimensionality problem.   \n",
    "\n",
    "Topic Modeling. That is an unsupervised clustering text-based method that assigns a membership score for each (item j, topic k) pair. Each topic is represented as a multinomial probability mass function over words in the corpus. It is a bayesian algorithm that assumes a Dirichlet prior for each topic and posteriors with probability of an item belonging to a topic.\n",
    "\n",
    "\n",
    "`User Characterization` is the process of crafting a feature vector for a user. User features might come from declared profiles or content-based; let's distinguish those scenarios. Declared Profiles are users' information, such as pre-defined interests and demographic data. Content-based feature sets aggregate every feature vector of items with which users interacted.\n",
    "\n",
    "\n",
    "\n",
    "Feature-Based methods then returns affinity between user and item based on their feature vectors. For Unsupervised methods, we calculate similarity between an user and item feature vector. In supervised ones, we model an observed rating by means of user and item vector. It is possible to model as a logistic regression, gaussian or pairwise preference score(Learning to rank). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811302f",
   "metadata": {},
   "source": [
    "### 2 - Collaborative Filtering methods\n",
    "\n",
    "Recommender algorithms that follow the collaborative filtering philosophy recommends items to users based on their commonalities with other users. This approach treats item ratings as a collaborative process where users help one another to identify interesting items. Three methods for craft recommendations are: user-user similarities, item-item similarities and Matrix factorization, where algorithms LSA and Alternating Least Squares have gained notable mentions by their great achievements.    \n",
    "\n",
    "In Matrix Factorization method, we decompose the user-item matrix into to low-rank matrices $U$ and $V$ with latent factors, which can by inherent features that model parameters from the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645ee62",
   "metadata": {},
   "source": [
    "This repo holds many other implementation of contemporary recommender algorithms: https://github.com/microsoft/recommenders/tree/main/recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ea747",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/recsys-series-part-7-the-3-variants-of-boltzmann-machines-for-collaborative-filtering-4c002af258f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac6956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
